{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7E7eZwJ7F5c"
   },
   "outputs": [],
   "source": [
    "#@title *Prepare* { display-mode: \"form\", run: \"auto\" }\n",
    "\n",
    "#@markdown # **Prepare the environment**\n",
    "#@markdown Execute to install necessary packages, modules, fonts\n",
    "\n",
    "#@markdown Mount Google Drive at /content/drive (your drive folder at /content/drive/MyDrive):\n",
    "mount_gdrive = True #@param {type:\"boolean\"}\n",
    "#@markdown Force mount again. Useful for bug cases:\n",
    "force_remount = False #@param {type:\"boolean\"}\n",
    "\n",
    "# remove the old log\n",
    "!rm -rf error_log.txt > /dev/null\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "except ImportError:\n",
    "    drive = None\n",
    "\n",
    "# mount Google Drive\n",
    "if mount_gdrive:\n",
    "    if drive is None:\n",
    "        print(\"Mounting skipped: google.colab is unavailable in this environment.\")\n",
    "    else:\n",
    "        print(\"Mounting your Google Drive | Waiting user Allow Access | \", end='')\n",
    "        try:\n",
    "            drive.mount('/content/drive/', force_remount=force_remount)\n",
    "        except Exception as e:\n",
    "            print(f\"[✗]: {e}\")\n",
    "\n",
    "# update code\n",
    "print(\"Ensuring the LeGen code is existing and updated...\", end='')\n",
    "repo_url = \"https://github.com/matheusbach/legen.git\"\n",
    "local_folder = \"/content/src\"  # LeGen source path\n",
    "\n",
    "# Create directory if it does not exist\n",
    "os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "# Try git status in the directory\n",
    "git_task = \"git fetch\"\n",
    "process = subprocess.Popen(git_task, cwd=local_folder, shell=True)\n",
    "return_code = process.wait()\n",
    "if return_code == 0:\n",
    "  git_task = \"git fetch && git reset --hard origin/main && git pull\"\n",
    "else:\n",
    "  shutil.rmtree(local_folder, ignore_errors=True)\n",
    "  os.makedirs(local_folder, exist_ok=True)\n",
    "  git_task = f\"git clone {repo_url} {local_folder}\"\n",
    "\n",
    "# If it is a git repo, fetch, reset, and pull. Else, clone.\n",
    "with open('/content/error_log.txt', 'a') as f:\n",
    "    process = subprocess.Popen(git_task, cwd=local_folder, shell=True, stderr=f)\n",
    "    return_code = process.wait()\n",
    "    print(\"[✔]\" if return_code == 0 else \"[✗]\")\n",
    "\n",
    "# install pip requirements.txt updating\n",
    "print(\"Installing or updating pip requirements...\", end='')\n",
    "with open('/content/error_log.txt', 'a') as f:\n",
    "    process = subprocess.Popen('pip3 install --upgrade $(grep -v \"whisperx-legen-fork\" requirements.txt | grep -v \"torch\") && pip3 install whisperx-legen-fork --upgrade', cwd=local_folder, shell=True, stderr=f)\n",
    "    return_code = process.wait()\n",
    "    print(\"[✔]\" if return_code == 0 else \"[✗]\")\n",
    "\n",
    "# install libcudnn8\n",
    "print(\"Install libcudnn8...\", end='')\n",
    "with open('/content/error_log.txt', 'a') as f:\n",
    "    process = subprocess.Popen('sudo apt install -y libcudnn8', cwd=local_folder, shell=True, stderr=f)\n",
    "    return_code = process.wait()\n",
    "    print(\"[✔]\" if return_code == 0 else \"[✗]\")\n",
    "\n",
    "# install ffmpeg and xvfb\n",
    "print(\"Installing FFmpeg and xvfb...\", end='')\n",
    "with open('/content/error_log.txt', 'a') as f:\n",
    "    process = subprocess.Popen('apt update -y ; apt install ffmpeg xvfb -y', shell=True, stderr=f)\n",
    "    return_code = process.wait()\n",
    "    print(\"[✔]\" if return_code == 0 else \"[✗]\")\n",
    "\n",
    "# install pip requirements.txt updating\n",
    "print(\"Installing fonts...\", end='')\n",
    "with open('/content/error_log.txt', 'a') as f:\n",
    "    process = subprocess.Popen('echo ttf-mscorefonts-installer msttcorefonts/accepted-mscorefonts-eula select true | debconf-set-selections && apt install -y ttf-mscorefonts-installer && fc-cache -f -v', shell=True, stderr=f)\n",
    "    return_code = process.wait()\n",
    "    print(\"[✔]\" if return_code == 0 else \"[✗]\")\n",
    "\n",
    "# create a virtual display\n",
    "os.system('Xvfb :1 -screen 0 2560x1440x8  &') # create virtual display with size 1600x1200 and 8 bit color. Color can be changed to 24, 16 or 8\n",
    "os.environ['DISPLAY'] = ':1.0' # tell X clients to use our virtual DISPLAY :1.0.\n",
    "\n",
    "print(\"\\nPreparation tasks done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bz77fHta9JxG"
   },
   "outputs": [],
   "source": [
    "#@title *Configure* { display-mode: \"form\", run: \"auto\" }\n",
    "#@markdown # **Define Software Settings**\n",
    "#@markdown ---\n",
    "#@markdown ## General Options\n",
    "#@markdown Set where your files are located (your Drive is the base /content/drive/MyDrive):\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "overwrite_existing = False #@param {type:\"boolean\"}\n",
    "normalize = False #@param {type:\"boolean\"}\n",
    "generate_srt = True #@param {type:\"boolean\"}\n",
    "generate_txt = False #@param {type:\"boolean\"}\n",
    "generate_embed_softsub = True #@param {type:\"boolean\"}\n",
    "generate_hardsub = True #@param {type:\"boolean\"}\n",
    "copy_extra_files = True #@param {type:\"boolean\"}\n",
    "\n",
    "input_path = \"/content/drive/MyDrive/LeGen/media\" #@param {type:\"string\"}\n",
    "download_path = \"/content/drive/MyDrive/LeGen/downloads\" #@param {type:\"string\"}  # yt-dlp stores media here with subtitles embedded in the MP4\n",
    "output_softsubs_path = \"/content/drive/MyDrive/LeGen/softsubs\" #@param {type:\"string\"}\n",
    "output_hardsubs_path = \"/content/drive/MyDrive/LeGen/hardsubs\" #@param {type:\"string\"}\n",
    "\n",
    "def _looks_like_url(value: str) -> bool:\n",
    "    try:\n",
    "        parsed = urlparse(value)\n",
    "        return parsed.scheme in (\"http\", \"https\") and bool(parsed.netloc)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# Create directories helper\n",
    "#@markdown Click the button below if you need to create the directories above:\n",
    "if \"_legen_create_dirs\" not in globals():\n",
    "    def _legen_create_dirs():\n",
    "        if input_path and not _looks_like_url(input_path):\n",
    "            os.makedirs(input_path, exist_ok=True)\n",
    "        elif _looks_like_url(input_path):\n",
    "            print(\"Input is a URL. Skipping local directory creation for it.\")\n",
    "        if download_path:\n",
    "            os.makedirs(download_path, exist_ok=True)\n",
    "        if generate_embed_softsub:\n",
    "            os.makedirs(output_softsubs_path, exist_ok=True)\n",
    "        if generate_hardsub:\n",
    "            os.makedirs(output_hardsubs_path, exist_ok=True)\n",
    "        print(\"Directories ready.\")\n",
    "try:\n",
    "    from google.colab import output as _colab_output\n",
    "    _colab_output.register_callback('legen_create_dirs', _legen_create_dirs)\n",
    "except Exception:\n",
    "    pass\n",
    "#@markdown\n",
    "#@markdown <button onclick=\"google.colab.kernel.invokeFunction('legen_create_dirs', [], {});\">Create directories</button>\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## Transcription Settings:\n",
    "transcription_engine = 'WhisperX' # @param [\"Whisper\", \"WhisperX\"]\n",
    "transcription_device = 'auto' #@param [\"auto\", \"cpu\", \"cuda\"]\n",
    "transcription_model = 'large-v3-turbo' #@param [\"tiny\", \"small\", \"medium\", \"large\", \"large-v1\", \"large-v2\", \"large-v3\", \"turbo\", \"large-v3-turbo\", \"distil-large-v2\", \"distil-medium.en\", \"distil-small.en\", \"distil-large-v3\"]\n",
    "transcription_vad = 'Silero' # @param [\"Silero\", \"Pyannote\"]\n",
    "compute_type = 'default' # @param [\"default\", \"int8\", \"int16\", \"float16\", \"float32\"]\n",
    "batch_size = 12 #@param {type:\"number\"}\n",
    "transcription_input_lang = 'auto detect' #@param [\"auto detect\", \"af\", \"am\", \"ar\", \"as\", \"az\", \"ba\", \"be\", \"bg\", \"bn\", \"bo\", \"br\", \"bs\", \"ca\", \"cs\", \"cy\", \"da\", \"de\", \"el\", \"en\", \"es\", \"et\", \"eu\", \"fa\", \"fi\", \"fo\", \"fr\", \"gl\", \"gu\", \"ha\", \"haw\", \"he\", \"hi\", \"hr\", \"ht\", \"hu\", \"hy\", \"id\", \"is\", \"it\", \"ja\", \"jw\", \"ka\", \"kk\", \"km\", \"kn\", \"ko\", \"la\", \"lb\", \"ln\", \"lo\", \"lt\", \"lv\", \"mg\", \"mi\", \"mk\", \"ml\", \"mn\", \"mr\", \"ms\", \"mt\", \"my\", \"ne\", \"nl\", \"nn\", \"no\", \"oc\", \"pa\", \"pl\", \"ps\", \"pt\", \"ro\", \"ru\", \"sa\", \"sd\", \"si\", \"sk\", \"sl\", \"sn\", \"so\", \"sq\", \"sr\", \"su\", \"sv\", \"sw\", \"ta\", \"te\", \"tg\", \"th\", \"tk\", \"tl\", \"tr\", \"tt\", \"uk\", \"ur\", \"uz\", \"vi\", \"yi\", \"yo\", \"zh\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## Translation Settings:\n",
    "#@markdown Set the destination language code. Set to same as original to skip translation\n",
    "target_language_code = 'pt-BR' #@param [\"af\", \"sq\", \"am\", \"ar\", \"hy\", \"as\", \"ay\", \"az\", \"bm\", \"eu\", \"be\", \"bn\", \"bho\", \"bs\", \"bg\", \"ca\", \"ceb\", \"zh-CN\", \"zh-TW\", \"co\", \"hr\", \"cs\", \"da\", \"dv\", \"doi\", \"nl\", \"en\", \"eo\", \"et\", \"ee\", \"fil\", \"fi\", \"fr\", \"fy\", \"gl\", \"ka\", \"de\", \"el\", \"gn\", \"gu\", \"ht\", \"ha\", \"haw\", \"he\", \"hi\", \"hmn\", \"hu\", \"is\", \"ig\", \"ilo\", \"id\", \"ga\", \"it\", \"ja\", \"jv\", \"kn\", \"kk\", \"km\", \"rw\", \"gom\", \"ko\", \"kri\", \"ku\", \"ckb\", \"ky\", \"lo\", \"la\", \"lv\", \"ln\", \"lt\", \"lg\", \"lb\", \"mk\", \"mai\", \"mg\", \"ms\", \"ml\", \"mt\", \"mi\", \"mr\", \"mni-Mtei\", \"lus\", \"mn\", \"my\", \"ne\", \"no\", \"ny\", \"or\", \"om\", \"ps\", \"fa\", \"pl\", \"pt-BR\", \"pt-PT\", \"pa\", \"qu\", \"ro\", \"ru\", \"sm\", \"sa\", \"gd\", \"nso\", \"sr\", \"st\", \"sn\", \"sd\", \"si\", \"sk\", \"sl\", \"so\", \"es\", \"su\", \"sw\", \"sv\", \"tl\", \"tg\", \"ta\", \"tt\", \"te\", \"th\", \"ti\", \"ts\", \"tr\", \"tk\", \"ak\", \"uk\", \"ur\", \"ug\", \"uz\", \"vi\", \"cy\", \"xh\", \"yi\", \"yo\", \"zu\"]\n",
    "#@markdown Select translation engine:\n",
    "translate_engine = 'google' #@param [\"google\", \"gemini\"]\n",
    "#@markdown If using Gemini, paste your API keys here (separate with commas or new lines):\n",
    "gemini_api_keys = '' #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## Video Settings:\n",
    "codec_video = \"h264\"  #@param [\"h264\", \"hevc\", \"mpeg4\"]\n",
    "video_hardware_api = \"auto\"  #@param [\"auto\", \"none\", \"nvenc\", \"vaapi\", \"amf\", \"v4l2m2m\", \"qsv\", \"videotoolbox\", \"cuvid\"]\n",
    "codec_audio = \"aac\"  #@param [\"aac\", \"libopus\", \"libmp3lame\", \"pcm_s16le\"]\n",
    "\n",
    "def collect_legen_settings():\n",
    "    subtitle_formats = []\n",
    "    if generate_srt:\n",
    "        subtitle_formats.append(\"srt\")\n",
    "    if generate_txt:\n",
    "        subtitle_formats.append(\"txt\")\n",
    "    if not subtitle_formats:\n",
    "        subtitle_formats = [\"srt\"]\n",
    "    gemini_keys = []\n",
    "    if translate_engine == 'gemini':\n",
    "        gemini_keys = [\n",
    "            key.strip()\n",
    "            for key in gemini_api_keys.replace(',', '\\n').splitlines()\n",
    "            if key.strip()\n",
    "        ]\n",
    "    return {\n",
    "        \"input_path\": input_path,\n",
    "        \"download_path\": download_path,\n",
    "        \"output_softsubs_path\": output_softsubs_path,\n",
    "        \"output_hardsubs_path\": output_hardsubs_path,\n",
    "        \"overwrite_existing\": overwrite_existing,\n",
    "        \"normalize\": normalize,\n",
    "        \"copy_extra_files\": copy_extra_files,\n",
    "        \"generate_srt\": generate_srt,\n",
    "        \"generate_txt\": generate_txt,\n",
    "        \"generate_embed_softsub\": generate_embed_softsub,\n",
    "        \"generate_hardsub\": generate_hardsub,\n",
    "        \"transcription_engine\": transcription_engine,\n",
    "        \"transcription_device\": transcription_device,\n",
    "        \"transcription_model\": transcription_model,\n",
    "        \"transcription_vad\": transcription_vad,\n",
    "        \"compute_type\": compute_type,\n",
    "        \"batch_size\": batch_size if transcription_engine == 'WhisperX' else None,\n",
    "        \"transcription_input_lang\": transcription_input_lang,\n",
    "        \"target_language_code\": target_language_code,\n",
    "        \"translate_engine\": translate_engine,\n",
    "        \"gemini_api_keys\": gemini_keys,\n",
    "        \"codec_video\": codec_video,\n",
    "        \"video_hardware_api\": video_hardware_api,\n",
    "        \"codec_audio\": codec_audio,\n",
    "        \"subtitle_formats\": subtitle_formats,\n",
    "        \"input_is_url\": _looks_like_url(input_path),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4KSJ9BL7JOs"
   },
   "outputs": [],
   "source": [
    "#@title *Run* { display-mode: \"form\" }\n",
    "#@markdown # **Run LeGen.py**\n",
    "\n",
    "if \"collect_legen_settings\" not in globals():\n",
    "    raise RuntimeError(\"Run the Configure cell before executing this step.\")\n",
    "\n",
    "print(\"Starting LeGen...\")\n",
    "import os\n",
    "import shlex\n",
    "import torch\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "  \n",
    "matmul_backend = getattr(torch.backends.cuda, \"matmul\", None)\n",
    "if matmul_backend is not None and hasattr(matmul_backend, \"fp32_precision\"):\n",
    "    matmul_backend.fp32_precision = \"tf32\"\n",
    "elif matmul_backend is not None and hasattr(matmul_backend, \"allow_tf32\"):\n",
    "    matmul_backend.allow_tf32 = True\n",
    "\n",
    "cudnn_conv_backend = getattr(torch.backends.cudnn, \"conv\", None)\n",
    "if cudnn_conv_backend is not None and hasattr(cudnn_conv_backend, \"fp32_precision\"):\n",
    "    cudnn_conv_backend.fp32_precision = \"tf32\"\n",
    "elif hasattr(torch.backends.cudnn, \"allow_tf32\"):\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "settings = collect_legen_settings()\n",
    "settings[\"transcription_vad\"] = settings[\"transcription_vad\"].lower()\n",
    "\n",
    "if '_looks_like_url' not in globals():\n",
    "    from urllib.parse import urlparse\n",
    "    def _looks_like_url(value: str) -> bool:\n",
    "        try:\n",
    "            parsed = urlparse(value)\n",
    "            return parsed.scheme in (\"http\", \"https\") and bool(parsed.netloc)\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "input_is_url = settings.get(\"input_is_url\", False)\n",
    "if not input_is_url:\n",
    "    os.makedirs(settings[\"input_path\"], exist_ok=True)\n",
    "else:\n",
    "    print(\"Input path is a URL. The downloader will fetch the media automatically.\")\n",
    "if settings.get(\"download_path\"):\n",
    "    os.makedirs(settings[\"download_path\"], exist_ok=True)\n",
    "if settings[\"generate_embed_softsub\"]:\n",
    "  os.makedirs(settings[\"output_softsubs_path\"], exist_ok=True)\n",
    "if settings[\"generate_hardsub\"]:\n",
    "  os.makedirs(settings[\"output_hardsubs_path\"], exist_ok=True)\n",
    "\n",
    "subtitle_formats_value = ','.join(settings[\"subtitle_formats\"])\n",
    "\n",
    "# build query\n",
    "query = f\" -i '{settings['input_path']}'\"\n",
    "query += f\" --output_softsubs '{settings['output_softsubs_path']}'\"\n",
    "query += f\" --output_hardsubs '{settings['output_hardsubs_path']}'\"\n",
    "if settings.get(\"download_path\"):\n",
    "    query += f\" --output_downloads {shlex.quote(settings['download_path'])}\"\n",
    "query += \" --overwrite\" if settings[\"overwrite_existing\"] else \"\"\n",
    "query += \" --norm\" if settings[\"normalize\"] else \"\"\n",
    "query += \" --copy_files\" if not settings[\"copy_extra_files\"] else \"\"\n",
    "query += f\" --subtitle_formats {shlex.quote(subtitle_formats_value)}\" if subtitle_formats_value else \"\"\n",
    "query += \" --disable_softsubs\" if not settings[\"generate_embed_softsub\"] else \"\"\n",
    "query += \" --disable_hardsubs\" if not settings[\"generate_hardsub\"] else \"\"\n",
    "query += f\" -ts:e {settings['transcription_engine'].lower()}\"\n",
    "query += f\" -ts:d {settings['transcription_device'].lower()}\"\n",
    "query += f\" -ts:m {settings['transcription_model']}\"\n",
    "query += f\" -ts:c {settings['compute_type']}\"\n",
    "query += f\" -ts:v {settings['transcription_vad']}\"\n",
    "query += f\" -ts:b {settings['batch_size']}\" if settings[\"batch_size\"] is not None else \"\"\n",
    "query += f\" --input_lang {settings['transcription_input_lang']}\" if settings[\"transcription_input_lang\"] != \"auto detect\" else \"\"\n",
    "query += f\" --translate {settings['target_language_code'].lower()}\"\n",
    "query += f\" --translate_engine {settings['translate_engine']}\"\n",
    "for key in settings[\"gemini_api_keys\"]:\n",
    "    query += f\" --gemini_api_key {shlex.quote(key)}\"\n",
    "query += f\" -c:v {settings['codec_video']}\" + (\"\" if settings['video_hardware_api'] == \"none\" else f\"_{settings['video_hardware_api']}\" if settings['video_hardware_api'] != \"auto\" else \"_nvenc\" if torch.cuda.is_available() else \"\")\n",
    "query += f\" -c:a {settings['codec_audio']}\"\n",
    "\n",
    "# run python script\n",
    "print(f\"command line: python3 /content/src/legen.py {query}\", end=\"\\n\\n\")\n",
    "!python3 /content/src/legen.py $query"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
